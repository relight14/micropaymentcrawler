Product Goal

Deliver results that match what the user truly wants right now‚Äîwhether that‚Äôs breaking news or deep historical analysis‚Äîby reading the conversation, detecting intent + timeframe, and querying the right rails with principled ranking and clear UX.

Core Ideas (that make it feel ‚Äúthis is EXACTLY what I needed‚Äù)

Conversation ‚Üí Research Brief (cheap, high leverage)
Compress the last 15‚Äì20 turns into a structured brief:

topic: the nucleus (e.g., Gaza peace deal)

subasks: terms sought (‚Äúwhat‚Äôs agreed‚Äù), stakeholders (‚Äúwho supports‚Äù), evaluation (‚Äúlasting peace prospects‚Äù)

entities: normalized (Israel, Hamas, Egypt, Qatar, US, UN)

timeframe: today / last 3 days / historical / ‚Äúsince 1990‚Äù

geography: region(s)

output bias: news / academic / business / data
Use a small model to produce ~150‚Äì250 words + key fields. Cache per session hash.

Dual classification: Intent √ó Temporal
Map the brief to:

Intent: news_event | business_trends | academic_causal | historical_explainer | regulatory/legal | data/statistics

Temporal: T0 (24h) | T1 (3d) | T7 (7d) | TH (historical)
This governs which rails run and their budget split.

Multi-Rail Querying (not rigid, but guided)
Run a portfolio of targeted searches (1‚Äì2 rails by default, more only if needed):

News rail (wire + majors + regional): Reuters, AP, BBC, NYT, WSJ, FT, Al Jazeera, Haaretz, Times of Israel

Policy rail: MEI, Brookings, Carnegie, CSIS, Atlantic Council

Scholarly rail: NBER, SSRN, Semantic Scholar/Crossref, .edu

Data rail: official statistics/government sources
For current events, allocate ~70% budget to news rail, 30% to policy.
For historical/causal, invert: scholarly/policy first, news second.

Rails are simple adapters; you can keep Tavily as the generic web rail and still emulate domain targeting via include/exclude lists & time windows.

Query Planning (from the Brief)
Generate one main query plus 2‚Äì3 facet queries, all grounded in entities/time:

Main: "Gaza peace deal 2025 ceasefire agreement terms supporters mediators Egypt Qatar US UN announced today"

Facets:

Terms/timeline: "deal terms clauses implementation monitoring verification"

Actors/support: "US Qatar Egypt UN positions supporters opponents"

Status/recency: "signed announced today entry into force ceasefire"
Each rail applies its own domain includes/excludes and time window.
Always exclude low-value domains upfront (Wikipedia, Reddit, Quora, Medium) and enforce at least one of the core entities in every query.

Reranking that fits the intent
Score each result locally (no extra API cost) on:

Recency: strong exponential decay for newsy intents; relaxed for historical

Topicality: cosine/BM25 vs. the Brief (title + snippet)

Authority: domain weights (wire services +0.6, majors +0.45, policy +0.4, scholarly +0.5, long-tail 0, penalize low-cred ‚àí1.0)

Diversity: cluster near-duplicates and keep 1 per cluster (MMR or simple URL/title dedupe)
Compose per intent, e.g.:

News: 0.45*recency + 0.35*topicality + 0.20*authority

Academic: 0.15*recency + 0.45*topicality + 0.40*authority

Smart guardrails (automatic, not annoying)

Freshness sentinel: If no T0 hits, auto-expand to T1; if still thin, say so and pivot to policy/scholarly analysis.

Entity sentinel: If top 3 don‚Äôt mention core entities, auto-inject them and retry once.

Mix sentinel: Enforce a minimum rail presence (e.g., news intent ‚Üí guarantee ‚â•1 wire result in top 3).

Explainability UX that builds trust

Intent banner: ‚Äúüß≠ Focus: Breaking news + policy analysis (last 72h)‚Äù

Filter chips: [All] [News] [Policy] [Scholarly] [Data] (client-side only)

‚ÄúWhy this result‚Äù: hover shows Recency/Authority/Topicality notes

Temporal badge per card: ‚ÄúPublished 3h ago‚Äù vs ‚Äú2019 (context)‚Äù

Cost control

Use small model for Brief + intent; cache Brief for 10‚Äì15 min.

Run one rail pass first; fallback pass only if <5 quality results.

Rerank locally; summarize only top K (e.g., 6) later.

Heavy model reserved for paid report generation.

Thin, pragmatic architecture
Modules

context_summarizer: builds Research Brief (small LLM)

intent_classifier: cheap rules + tiny LLM backstop

query_planner: builds main + facet queries per rail

search_adapter: unifies Tavily/Bing/NewsAPI/Scholar/etc.

reranker: recency/authority/topicality/diversity

sentinels: freshness/entity/mix auto-corrections

presenter: badges, filters, ‚Äúwhy this result‚Äù

Pseudocode (orchestrator)
def research_search(conversation, user_query):
    brief = get_or_build_brief(conversation, user_query)  # cached small-LLM summary
    intent, bucket = classify_intent_and_time(brief)      # rules + tiny LLM

    rails = choose_rails(intent)                          # e.g., ["news","policy"]
    queries = build_queries(brief, intent)                # main + facets
    includes, excludes, window = rail_configs(intent, bucket)

    results = []
    results += search_adapter(rails, queries.main, includes, excludes, window)
    good = quality_filter(results, require_entities=brief.entities)

    if len(good) < 5:
        results += search_adapter(rails, queries.facet1, includes, excludes, window)

    ranked = rerank_and_diversify(results, brief, intent)
    ranked = apply_sentinels(ranked, brief, intent, bucket)  # may auto-broaden window once

    return present(ranked[:10], intent=intent, window=window)

Domain sets (editable JSON; easy for your team to tune)
{
  "news_major": ["reuters.com","apnews.com","bbc.com","nytimes.com","wsj.com","ft.com"],
  "regional_me": ["aljazeera.com","haaretz.com","timesofisrael.com"],
  "policy": ["mei.edu","brookings.edu","carnegieendowment.org","csis.org","atlanticcouncil.org"],
  "scholarly": ["nber.org",".edu","ssrn.com","semanticscholar.org"],
  "exclude": ["wikipedia.org","reddit.com","quora.com","medium.com"]
}

UX details that make it sing

Top strip: ‚Äúüß≠ Focus: Breaking news (24h) + policy analysis‚Äù ¬∑ ‚ÄúChange focus ‚Üí [News] [Policy] [Scholarly] [All]‚Äù

Card badges: üì∞ News ¬∑ üèõÔ∏è Policy ¬∑ üéì Scholarly ¬∑ üìä Data; show publish time + source logo

Empty/low-freshness state: ‚ÄúNo verified reports in last 24h. Showing best recent analysis.‚Äù

One-tap refinements: Add actors ¬∑ Show deal terms ¬∑ Expand time window (they simply toggle which facet you run)

Evaluation (so we know it‚Äôs better)

Top-3 precision@intent (human-rated): Is the #1 result from a suitable rail and within the expected time window?

Freshness@news: % of top-3 from last 24‚Äì72h when ‚Äútoday/now‚Äù detected

CTR by rail: Are users clicking the rail we emphasized?

Time-to-first-credible: ms until a Reuters/AP/BBC/major appears in viewport

User feedback quick-tap: ‚ÄúShow me more [News/Policy/Scholarly] next time‚Äù

Rollout path (1 sprint each; costs stay low)

Sprint A (MVP leap): Brief + Intent/Temporal ‚Üí Query planner ‚Üí Rail includes/excludes ‚Üí Local reranker ‚Üí Intent banner + chips.
Sprint B (Polish): Sentinels + ‚ÄúWhy this result‚Äù + diversity/dup collapse.
Sprint C (Depth): Data rail, scholarly adapter, per-user rail weighting from clicks.

Why this works

It respects intent and time (the two biggest determinants of relevance).

It mixes depth and currency without being rigid.

It‚Äôs explainable (badges, banner, why-this-result).

It‚Äôs cheap (one small LLM, one search pass; fallback only when thin).

It scales into your paid Sonnet-quality report seamlessly.

If you want, I can turn this into a compact search_orchestrator.py scaffold (functions + config stubs + a couple of unit tests) so your agent can drop it in and iterate immediately.

You said:
ok and one additional question, you can keep the answer brief.  if we highlight specific publications will that make our search query too rigid? 
ChatGPT said:

Good question ‚Äî it depends how you highlight them.

‚úÖ If you use them as soft boosts (e.g., in reranking or query weighting) ‚Äî no problem. The search stays flexible, and those outlets just rise when relevant.

‚ùå If you hard-code them into the query with site: filters ‚Äî yes, it becomes rigid and may miss breaking or niche coverage.

Best approach:

Use broad queries + domain weighting in reranking (Reuters +0.6, MEI +0.4, etc.).

Only add explicit site: clauses for intent-critical rails (e.g., scholarly or policy).

That gives you consistent quality without constraining discovery.