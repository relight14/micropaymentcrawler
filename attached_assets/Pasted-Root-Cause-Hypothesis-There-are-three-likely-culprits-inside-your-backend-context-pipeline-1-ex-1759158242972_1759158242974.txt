Root Cause Hypothesis

There are three likely culprits inside your backend context pipeline:

1. _extract_research_context(user_id) Looks at Wrong Table or Timestamp

It might be querying only newer messages after the login

Or it's hitting the wrong keyspace (e.g., looking for user_abc but checking anon_abc)

2. Bad Prompt Construction

Your summarization pipeline may accidentally use the wrong messages

Token limit trimming might be chopping context prematurely

You might be repeating or re-summarizing identical low-value messages, hence the repetition

3. Message Quality Filter Too Strict

If you're filtering messages (e.g., must be user messages, length > 10, etc), and migrated messages don’t pass that filter

Or you aren’t including assistant responses, which may be where the relevant content lives (e.g., past summaries or clarifications)

✅ Next Steps for Backend Fix
Step 1: Inspect _extract_research_context(user_id)

Log what it’s pulling:

messages = get_recent_messages(user_id)
logger.info(f"Extracted {len(messages)} for context from user_id={user_id}")
logger.info(f"Message preview: {[m.text[:80] for m in messages]}")


Check:

Are these messages the migrated ones?

Are they before the login timestamp?

Do they mention the expected topic ("climate change")?

Step 2: Improve Filtering Logic

In your context construction pipeline, you probably have something like:

relevant_messages = [m for m in messages if m.role == 'user' and len(m.text) > 20]


Change this to:

# Include both user and assistant messages
relevant_messages = [
    m for m in messages
    if m.role in ['user', 'assistant'] and len(m.text.strip()) > 10
]

Step 3: Improve De-Duplication

That repetitive context (e.g., "recent articles on...") is a sign of bad de-duping.

If you’re summarizing messages like this:

" ".join([m.text for m in relevant_messages])


Add de-duplication or semantic filtering:

seen = set()
clean_messages = []
for m in relevant_messages:
    if m.text not in seen:
        clean_messages.append(m.text)
        seen.add(m.text)


Or better: use embedding similarity to dedupe.

✅ Final Fix Path

 Migration logic ✅

 Header issue fixed ✅

 Fix _extract_research_context() to use correct user_id + deeper message history

 Include richer message roles (assistant)

 De-dupe repetitive phrases

 Log final constructed prompt to validate